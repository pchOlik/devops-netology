## Домашнее задание к занятию "3.5. Файловые системы"

#### 1. Узнайте о [sparse](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D0%B7%D1%80%D0%B5%D0%B6%D1%91%D0%BD%D0%BD%D1%8B%D0%B9_%D1%84%D0%B0%D0%B9%D0%BB) (разряженных) файлах.

Разреженные – это специальные файлы, которые с большей эффективностью используют файловую систему, они не позволяют ФС занимать свободное дисковое пространство носителя, когда разделы не заполнены. То есть, «пустое место» будет задействовано только при необходимости. Пустая информация в виде нулей, будет хранится в блоке метаданных ФС. Поэтому, разреженные файлы изначально занимают меньший объем носителя, чем их реальный объем.

#### 2.Могут ли файлы, являющиеся жесткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?
Нет, так как жесткая ссылка это не сам файл, а лишь


#### 3. Сделайте `vagrant destroy` на имеющийся инстанс Ubuntu. Замените содержимое Vagrantfile следующим:

```bash
path_to_disk_folder = './disks'

host_params = {
    'disk_size' => 2560,
    'disks'=>[1, 2],
    'cpus'=>2,
    'memory'=>2048,
    'hostname'=>'sysadm-fs',
    'vm_name'=>'sysadm-fs'
}
Vagrant.configure("2") do |config|
    config.vm.box = "bento/ubuntu-20.04"
    config.vm.hostname=host_params['hostname']
    config.vm.provider :virtualbox do |v|

        v.name=host_params['vm_name']
        v.cpus=host_params['cpus']
        v.memory=host_params['memory']

        host_params['disks'].each do |disk|
            file_to_disk=path_to_disk_folder+'/disk'+disk.to_s+'.vdi'
            unless File.exist?(file_to_disk)
                v.customize ['createmedium', '--filename', file_to_disk, '--size', host_params['disk_size']]
            end
            v.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', disk.to_s, '--device', 0, '--type', 'hdd', '--medium', file_to_disk]
        end
    end
    config.vm.network "private_network", type: "dhcp"
end
```
    Данная конфигурация создаст новую виртуальную машину с двумя дополнительными неразмеченными дисками по 2.5 Гб.

```shell
vagrant@vagrant:~$ lsblk
NAME                      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
loop0                       7:0    0 61.9M  1 loop /snap/core20/1405
loop1                       7:1    0 79.9M  1 loop /snap/lxd/22923
loop2                       7:2    0 44.7M  1 loop /snap/snapd/15534
sda                         8:0    0   64G  0 disk
├─sda1                      8:1    0    1M  0 part
├─sda2                      8:2    0    2G  0 part /boot
└─sda3                      8:3    0   62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0   31G  0 lvm  /
sdb                         8:16   0  2.5G  0 disk
sdc                         8:32   0  2.5G  0 disk
vagrant@vagrant:~$
```

####   4. Используя `fdisk`, разбейте первый диск на 2 раздела: 2 Гб, оставшееся пространство.

```shell

vagrant@vagrant:~$ sudo fdisk /dev/sdb

Welcome to fdisk (util-linux 2.37.2).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Device does not contain a recognized partition table.
Created a new DOS disklabel with disk identifier 0xf4690278.

Command (m for help):


Command (m for help): n
Partition type
   p   primary (0 primary, 0 extended, 4 free)
   e   extended (container for logical partitions)
Select (default p): p
Partition number (1-4, default 1): 1
First sector (2048-5242879, default 2048):
Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-5242879, default 5242879): +2G

Created a new partition 1 of type 'Linux' and of size 2 GiB.

Command (m for help): n
Partition type
   p   primary (1 primary, 0 extended, 3 free)
   e   extended (container for logical partitions)
Select (default p): p
Partition number (2-4, default 2):
First sector (4196352-5242879, default 4196352):
Last sector, +/-sectors or +/-size{K,M,G,T,P} (4196352-5242879, default 5242879):

Created a new partition 2 of type 'Linux' and of size 511 MiB.

Command (m for help): w
The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks.

vagrant@vagrant:~$


```
#### 5. Используя `sfdisk`, перенесите данную таблицу разделов на второй диск.

```shell
vagrant@vagrant:~$ sudo sfdisk -d /dev/sdb > sdb.dump
vagrant@vagrant:~$ sudo sfdisk -d /dev/sdc < sdb.dump
sfdisk: /dev/sdc: does not contain a recognized partition table
vagrant@vagrant:~$ sudo sfdisk /dev/sdc < sdb.dump
Checking that no-one is using this disk right now ... OK

Disk /dev/sdc: 2.5 GiB, 2684354560 bytes, 5242880 sectors
Disk model: VBOX HARDDISK
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes

>>> Script header accepted.
>>> Script header accepted.
>>> Script header accepted.
>>> Script header accepted.
>>> Script header accepted.
>>> Created a new DOS disklabel with disk identifier 0xf4690278.
/dev/sdc1: Created a new partition 1 of type 'Linux' and of size 2 GiB.
/dev/sdc2: Created a new partition 2 of type 'Linux' and of size 511 MiB.
/dev/sdc3: Done.

New situation:
Disklabel type: dos
Disk identifier: 0xf4690278

Device     Boot   Start     End Sectors  Size Id Type
/dev/sdc1          2048 4196351 4194304    2G 83 Linux
/dev/sdc2       4196352 5242879 1046528  511M 83 Linux

The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks.
vagrant@vagrant:~$ lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS
loop0                       7:0    0  61.9M  1 loop /snap/core20/1405
loop1                       7:1    0  79.9M  1 loop /snap/lxd/22923
loop3                       7:3    0  49.8M  1 loop /snap/snapd/18357
loop4                       7:4    0  63.3M  1 loop /snap/core20/1822
loop5                       7:5    0 111.9M  1 loop /snap/lxd/24322
sda                         8:0    0    64G  0 disk
├─sda1                      8:1    0     1M  0 part
├─sda2                      8:2    0     2G  0 part /boot
└─sda3                      8:3    0    62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0    31G  0 lvm  /
sdb                         8:16   0   2.5G  0 disk
├─sdb1                      8:17   0     2G  0 part
└─sdb2                      8:18   0   511M  0 part
sdc                         8:32   0   2.5G  0 disk
├─sdc1                      8:33   0     2G  0 part
└─sdc2                      8:34   0   511M  0 part

```

## Соберите mdadm RAID1 на паре разделов 2 Гб.

```shell

vagrant@vagrant:~$ sudo mdadm --create /dev/md0 --leve=1 --raid-devices=2 /dev/sd[bc]1
mdadm: Note: this array has metadata at the start and
    may not be suitable as a boot device.  If you plan to
    store '/boot' on this device please ensure that
    your boot-loader understands md/v1.x metadata, or use
    --metadata=0.90
Continue creating array? y
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
vagrant@vagrant:~$ lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINTS
loop0                       7:0    0  61.9M  1 loop  /snap/core20/1405
loop1                       7:1    0  79.9M  1 loop  /snap/lxd/22923
loop3                       7:3    0  49.8M  1 loop  /snap/snapd/18357
loop4                       7:4    0  63.3M  1 loop  /snap/core20/1822
loop5                       7:5    0 111.9M  1 loop  /snap/lxd/24322
sda                         8:0    0    64G  0 disk
├─sda1                      8:1    0     1M  0 part
├─sda2                      8:2    0     2G  0 part  /boot
└─sda3                      8:3    0    62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0    31G  0 lvm   /
sdb                         8:16   0   2.5G  0 disk
├─sdb1                      8:17   0     2G  0 part
│ └─md0                     9:0    0     2G  0 raid1
└─sdb2                      8:18   0   511M  0 part
sdc                         8:32   0   2.5G  0 disk
├─sdc1                      8:33   0     2G  0 part
│ └─md0                     9:0    0     2G  0 raid1
└─sdc2                      8:34   0   511M  0 part

```

### 7. Соберите `mdadm` RAID0 на второй паре маленьких разделов.

```shell

vagrant@vagrant:~$ sudo mdadm --create /dev/md1 --leve=0 --raid-devices=2 /dev/sd[bc]2
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md1 started.
vagrant@vagrant:~$ lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINTS
loop0                       7:0    0  61.9M  1 loop  /snap/core20/1405
loop1                       7:1    0  79.9M  1 loop  /snap/lxd/22923
loop3                       7:3    0  49.8M  1 loop  /snap/snapd/18357
loop4                       7:4    0  63.3M  1 loop  /snap/core20/1822
loop5                       7:5    0 111.9M  1 loop  /snap/lxd/24322
sda                         8:0    0    64G  0 disk
├─sda1                      8:1    0     1M  0 part
├─sda2                      8:2    0     2G  0 part  /boot
└─sda3                      8:3    0    62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0    31G  0 lvm   /
sdb                         8:16   0   2.5G  0 disk
├─sdb1                      8:17   0     2G  0 part
│ └─md0                     9:0    0     2G  0 raid1
└─sdb2                      8:18   0   511M  0 part
  └─md1                     9:1    0  1018M  0 raid0
sdc                         8:32   0   2.5G  0 disk
├─sdc1                      8:33   0     2G  0 part
│ └─md0                     9:0    0     2G  0 raid1
└─sdc2                      8:34   0   511M  0 part
  └─md1                     9:1    0  1018M  0 raid0
vagrant@vagrant:~$

```

#### 8.Создайте 2 независимых PV на получившихся md-устройствах.

```shell
vagrant@vagrant:~$ sudo pvcreate /dev/md0
  Physical volume "/dev/md0" successfully created.
vagrant@vagrant:~$ sudo pvcreate /dev/md1
  Physical volume "/dev/md1" successfully created.
vagrant@vagrant:~$

```


#### 9. Создайте общую volume-group на этих двух PV.

```shell
vagrant@vagrant:~$ sudo vgcreate volume-group /dev/md0 /dev/md1
  Volume group "volume-group" successfully created
vagrant@vagrant:~$ sudo vgs
  VG           #PV #LV #SN Attr   VSize   VFree
  ubuntu-vg      1   1   0 wz--n- <62.00g 31.00g
  volume-group   2   0   0 wz--n-  <2.99g <2.99g
vagrant@vagrant:~$

```


#### 10. Создайте LV размером 100 Мб, указав его расположение на PV с RAID0.

```shell
vagrant@vagrant:~$ sudo lvcreate -L100m -n LV volume-group /dev/md1
  Logical volume "LV" created.
vagrant@vagrant:~$ sudo lvs
  LV        VG           Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  ubuntu-lv ubuntu-vg    -wi-ao---- <31.00g
  LV        volume-group -wi-a----- 100.00m
vagrant@vagrant:~$

```

#### 11. Создайте `mkfs.ext4` ФС на получившемся LV.
```shell
vagrant@vagrant:~$ sudo mkfs.ext4 -L netology-ext4 -m 1 /dev/mapper/volume--group-LV
mke2fs 1.46.5 (30-Dec-2021)
Creating filesystem with 25600 4k blocks and 25600 inodes

Allocating group tables: done
Writing inode tables: done
Creating journal (1024 blocks): done
Writing superblocks and filesystem accounting information: done

vagrant@vagrant:~$
```

#### 12. Смонтируйте этот раздел в любую директорию, например, `/tmp/new`.
```shell
vagrant@vagrant:~$ sudo mount /dev/mapper/volume--group-LV /tmp/new/
vagrant@vagrant:~$ mount | grep /tmp/new
/dev/mapper/volume--group-LV on /tmp/new type ext4 (rw,relatime,stripe=256)
vagrant@vagrant:~$ df -h
Filesystem                         Size  Used Avail Use% Mounted on
tmpfs                               98M 1016K   97M   2% /run
/dev/mapper/ubuntu--vg-ubuntu--lv   31G  3.8G   26G  13% /
tmpfs                              486M     0  486M   0% /dev/shm
tmpfs                              5.0M     0  5.0M   0% /run/lock
/dev/sda2                          2.0G  126M  1.7G   7% /boot
vagrant                            466G  4.2G  462G   1% /vagrant
tmpfs                               98M  4.0K   98M   1% /run/user/1000
/dev/mapper/volume--group-LV        90M   24K   87M   1% /tmp/new
vagrant@vagrant:~$
```

#### 13. Поместите туда тестовый файл, например `wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz`.
```shell
vagrant@vagrant:~$ cd /tmp/new/
vagrant@vagrant:/tmp/new$ wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz.
/tmp/new/test.gz.: Permission denied
vagrant@vagrant:/tmp/new$ sudo wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.g
z.
--2023-02-18 19:00:31--  https://mirror.yandex.ru/ubuntu/ls-lR.gz
Resolving mirror.yandex.ru (mirror.yandex.ru)... 213.180.204.183, 2a02:6b8::183
Connecting to mirror.yandex.ru (mirror.yandex.ru)|213.180.204.183|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 24770163 (24M) [application/octet-stream]
Saving to: ‘/tmp/new/test.gz.’

/tmp/new/test.gz.       100%[==============================>]  23.62M  3.69MB/s    in 8.0s

2023-02-18 19:00:39 (2.94 MB/s) - ‘/tmp/new/test.gz.’ saved [24770163/24770163]

vagrant@vagrant:/tmp/new$
```

#### 14. Прикрепите вывод `lsblk`.
```shell
-bash: lslbk: command not found
vagrant@vagrant:/tmp/new$ lsblk
NAME                      MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINTS
loop0                       7:0    0  61.9M  1 loop  /snap/core20/1405
loop1                       7:1    0  79.9M  1 loop  /snap/lxd/22923
loop3                       7:3    0  49.8M  1 loop  /snap/snapd/18357
loop4                       7:4    0  63.3M  1 loop  /snap/core20/1822
loop5                       7:5    0 111.9M  1 loop  /snap/lxd/24322
sda                         8:0    0    64G  0 disk
├─sda1                      8:1    0     1M  0 part
├─sda2                      8:2    0     2G  0 part  /boot
└─sda3                      8:3    0    62G  0 part
  └─ubuntu--vg-ubuntu--lv 253:0    0    31G  0 lvm   /
sdb                         8:16   0   2.5G  0 disk
├─sdb1                      8:17   0     2G  0 part
│ └─md0                     9:0    0     2G  0 raid1
└─sdb2                      8:18   0   511M  0 part
  └─md1                     9:1    0  1018M  0 raid0
    └─volume--group-LV    253:1    0   100M  0 lvm   /tmp/new
sdc                         8:32   0   2.5G  0 disk
├─sdc1                      8:33   0     2G  0 part
│ └─md0                     9:0    0     2G  0 raid1
└─sdc2                      8:34   0   511M  0 part
  └─md1                     9:1    0  1018M  0 raid0
    └─volume--group-LV    253:1    0   100M  0 lvm   /tmp/new
vagrant@vagrant:/tmp/new$
```

#### 15. Протестируйте целостность файла:

    ```bash
    root@vagrant:~# gzip -t /tmp/new/test.gz
    root@vagrant:~# echo $?
    0
    ```
```shell
vagrant@vagrant:/tmp/new$ sudo gzip -t /tmp/new/test.gz.
vagrant@vagrant:/tmp/new$ echo $?
0
vagrant@vagrant:/tmp/new$
```

#### 16. Используя pvmove, переместите содержимое PV с RAID0 на RAID1.
```shell
vagrant@vagrant:~$ sudo pvmove -n LV /dev/md1 /dev/md0
  /dev/md1: Moved: 16.00%

  /dev/md1: Moved: 100.00%
```

#### 17. Сделайте `--fail` на устройство в вашем RAID1 md.
```shell
vagrant@vagrant:~$ sudo mdadm --fail /dev/md0 /dev/sdb1
mdadm: set /dev/sdb1 faulty in /dev/md0
```

#### 18. Подтвердите выводом `dmesg`, что RAID1 работает в деградированном состоянии.
```shell

[ 2797.399018] md/raid1:md0: Disk failure on sdb1, disabling device.
               md/raid1:md0: Operation continuing on 1 devices.
vagrant@vagrant:~$
```

#### 19. Протестируйте целостность файла, несмотря на "сбойный" диск он должен продолжать быть доступен:

    ```bash
    root@vagrant:~# gzip -t /tmp/new/test.gz
    root@vagrant:~# echo $?
    0
    ```
```shell

vagrant@vagrant:~$ sudo  gzip -t /tmp/new/test.gz.
vagrant@vagrant:~$ echo $?
0
vagrant@vagrant:~$
```

#### 20. Погасите тестовый хост, `vagrant destroy`.

```shell
PS D:\!VM\VM1> vagrant global-status
id       name    provider   state   directory
------------------------------------------------------------------------
3eb5421  default virtualbox running D:/!VM
0c98853  default virtualbox running D:/!VM/VM1

The above shows information about all known Vagrant environments
on this machine. This data is cached and may not be completely
up-to-date (use "vagrant global-status --prune" to prune invalid
entries). To interact with any of the machines, you can go to that
directory and run Vagrant, or you can use the ID directly with
Vagrant commands from any directory. For example:
"vagrant destroy 1a2b3c4d"
PS D:\!VM\VM1> vagrant destroy  0c98853
```